import pathlib
import textwrap
import google.generativeai as genai
import streamlit as st
import random

# few-shot í”„ë¡¬í”„íŠ¸ êµ¬ì„± í•¨ìˆ˜
def try_generate_content(api_key, prompt_parts):
    # API í‚¤ë¥¼ ì„¤ì •
    genai.configure(api_key=api_key)
    
    # ì„¤ì •ëœ ëª¨ë¸ ë³€ê²½
    model = genai.GenerativeModel(model_name="gemini-1.0-pro",
                                  generation_config={
                                      "temperature": 0.9,
                                      "top_p": 1,
                                      "top_k": 1,
                                      "max_output_tokens": 2048,
                                  },
                                  safety_settings=[
                                      {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
                                      {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
                                      {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
                                      {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
                                  ])
    try:
        # ì½˜í…ì¸  ìƒì„± ì‹œë„
        response = model.generate_content(prompt_parts)
        return response.text
    except Exception as e:
        # ì˜ˆì™¸ ë°œìƒì‹œ None ë°˜í™˜
        print(f"API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        return None

# ìŠ¤íŠ¸ë¦¼ë¦¿ ì•± ì¸í„°í˜ì´ìŠ¤ êµ¬ì„±
st.title("ì—°êµ¬ê³„íšì„œ ì‘ì„± ë„ìš°ë¯¸ ğŸ“")

# ì‚¬ì´ë“œë°”ì— API í‚¤ ì…ë ¥ë€ ì¶”ê°€ ë° ì•ˆë‚´ ë¬¸êµ¬
with st.sidebar:
    user_api_key = st.text_input("API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”:", type="password")
    st.write("""
    ğŸ’¡ [API í‚¤ ë°œê¸‰ ë°›ê¸°](https://aistudio.google.com/app/apikey)
    """)

# API í‚¤ ì„¤ì • í•¨ìˆ˜
def configure_api(api_key):
    genai.configure(api_key=api_key)

if user_api_key:
    configure_api(user_api_key)
else:
    st.error("API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

# ì—°êµ¬ ì£¼ì œ ì…ë ¥
if "step" not in st.session_state:
    st.session_state.step = 0
    st.session_state.details = []

left_col, right_col = st.columns(2)

with left_col:
    if st.session_state.step == 0:
        research_topic = st.text_input("ì—°êµ¬ ì£¼ì œë¥¼ ì…ë ¥í•˜ì„¸ìš”. âœï¸")
        if st.button("ë‹¤ìŒ ë‹¨ê³„", key="next_step_0"):
            if research_topic:
                st.session_state.details.append(f"ì—°êµ¬ ì£¼ì œ: {research_topic}")
                st.session_state.step += 1

    if st.session_state.step == 1:
        if "independent_variable_options" not in st.session_state:
            prompt = f"ì—°êµ¬ ì£¼ì œ: {st.session_state.details[0]}\në…ë¦½ë³€ì¸ì— ëŒ€í•œ ì„¸ ê°€ì§€ ì„ íƒì§€ë¥¼ ê°ê° 1ì¤„ë¡œ ì œê³µí•´ì£¼ì„¸ìš”."
            model = genai.GenerativeModel(model_name="gemini-1.0-pro",
                                          generation_config={
                                              "temperature": 0.7,
                                              "max_output_tokens": 150,
                                          })
            try:
                response = model.generate_content([prompt])
                st.session_state.independent_variable_options = response.text.split('\n')
            except Exception as e:
                st.error(f"API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
                st.session_state.independent_variable_options = []

        option = st.radio("ë…ë¦½ë³€ì¸ ì„ íƒì§€", st.session_state.independent_variable_options + ["ì§ì ‘ ì…ë ¥"], key="independent_variable")
        if option == "ì§ì ‘ ì…ë ¥":
            option = st.text_input("ë…ë¦½ë³€ì¸ì„ ì…ë ¥í•˜ì„¸ìš”:", key="independent_variable_input")

        if st.button("ë‹¤ìŒ ë‹¨ê³„", key="next_step_1"):
            st.session_state.details.append(f"ë…ë¦½ë³€ì¸: {option}")
            st.session_state.step += 1

    if st.session_state.step == 2:
        if "dependent_variable_options" not in st.session_state:
            prompt = f"ì—°êµ¬ ì£¼ì œ: {st.session_state.details[0]}\në…ë¦½ë³€ì¸: {st.session_state.details[1]}\nì¢…ì†ë³€ì¸ì— ëŒ€í•œ ì„¸ ê°€ì§€ ì„ íƒì§€ë¥¼ ê°ê° 1ì¤„ë¡œ ì œê³µí•´ì£¼ì„¸ìš”."
            model = genai.GenerativeModel(model_name="gemini-1.0-pro",
                                          generation_config={
                                              "temperature": 0.7,
                                              "max_output_tokens": 150,
                                          })
            try:
                response = model.generate_content([prompt])
                st.session_state.dependent_variable_options = response.text.split('\n')
            except Exception as e:
                st.error(f"API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
                st.session_state.dependent_variable_options = []

        option = st.radio("ì¢…ì†ë³€ì¸ ì„ íƒì§€", st.session_state.dependent_variable_options + ["ì§ì ‘ ì…ë ¥"], key="dependent_variable")
        if option == "ì§ì ‘ ì…ë ¥":
            option = st.text_input("ì¢…ì†ë³€ì¸ì„ ì…ë ¥í•˜ì„¸ìš”:", key="dependent_variable_input")

        if st.button("ë‹¤ìŒ ë‹¨ê³„", key="next_step_2"):
            st.session_state.details.append(f"ì¢…ì†ë³€ì¸: {option}")
            st.session_state.step += 1

    if st.session_state.step == 3:
        if "research_subject_options" not in st.session_state:
            prompt = f"ì—°êµ¬ ì£¼ì œ: {st.session_state.details[0]}\në…ë¦½ë³€ì¸: {st.session_state.details[1]}\nì¢…ì†ë³€ì¸: {st.session_state.details[2]}\nì—°êµ¬ëŒ€ìƒì— ëŒ€í•œ ì„¸ ê°€ì§€ ì„ íƒì§€ë¥¼ ê°ê° 1ì¤„ë¡œ ì œê³µí•´ì£¼ì„¸ìš”."
            model = genai.GenerativeModel(model_name="gemini-1.0-pro",
                                          generation_config={
                                              "temperature": 0.7,
                                              "max_output_tokens": 150,
                                          })
            try:
                response = model.generate_content([prompt])
                st.session_state.research_subject_options = response.text.split('\n')
            except Exception as e:
                st.error(f"API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
                st.session_state.research_subject_options = []

        option = st.radio("ì—°êµ¬ëŒ€ìƒ ì„ íƒì§€", st.session_state.research_subject_options + ["ì§ì ‘ ì…ë ¥"], key="research_subject")
        if option == "ì§ì ‘ ì…ë ¥":
            option = st.text_input("ì—°êµ¬ëŒ€ìƒì„ ì…ë ¥í•˜ì„¸ìš”:", key="research_subject_input")

        if st.button("ë‹¤ìŒ ë‹¨ê³„", key="next_step_3"):
            st.session_state.details.append(f"ì—°êµ¬ëŒ€ìƒ: {option}")
            st.session_state.step += 1

    if st.session_state.step == 4:
        if "research_method_options" not in st.session_state:
            prompt = f"ì—°êµ¬ ì£¼ì œ: {st.session_state.details[0]}\në…ë¦½ë³€ì¸: {st.session_state.details[1]}\nì¢…ì†ë³€ì¸: {st.session_state.details[2]}\nì—°êµ¬ëŒ€ìƒ: {st.session_state.details[3]}\nì—°êµ¬ë°©ë²•ì— ëŒ€í•œ ì„¸ ê°€ì§€ ì„ íƒì§€ë¥¼ ê°ê° 1ì¤„ë¡œ ì œê³µí•´ì£¼ì„¸ìš”."
            model = genai.GenerativeModel(model_name="gemini-1.0-pro",
                                          generation_config={
                                              "temperature": 0.7,
                                              "max_output_tokens": 150,
                                          })
            try:
                response = model.generate_content([prompt])
                st.session_state.research_method_options = response.text.split('\n')
            except Exception as e:
                st.error(f"API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
                st.session_state.research_method_options = []

        option = st.radio("ì—°êµ¬ë°©ë²• ì„ íƒì§€", st.session_state.research_method_options + ["ì§ì ‘ ì…ë ¥"], key="research_method")
        if option == "ì§ì ‘ ì…ë ¥":
            option = st.text_input("ì—°êµ¬ë°©ë²•ì„ ì…ë ¥í•˜ì„¸ìš”:", key="research_method_input")

        if st.button("ë‹¤ìŒ ë‹¨ê³„", key="next_step_4"):
            st.session_state.details.append(f"ì—°êµ¬ë°©ë²•: {option}")
            st.session_state.step += 1

    if st.session_state.step == 5:
        if "data_collection_method_options" not in st.session_state:
            prompt = f"ì—°êµ¬ ì£¼ì œ: {st.session_state.details[0]}\në…ë¦½ë³€ì¸: {st.session_state.details[1]}\nì¢…ì†ë³€ì¸: {st.session_state.details[2]}\nì—°êµ¬ëŒ€ìƒ: {st.session_state.details[3]}\nì—°êµ¬ë°©ë²•: {st.session_state.details[4]}\në°ì´í„° ìˆ˜ì§‘ ë°©ë²•ì— ëŒ€í•œ ì„¸ ê°€ì§€ ì„ íƒì§€ë¥¼ ê°ê° 1ì¤„ë¡œ ì œê³µí•´ì£¼ì„¸ìš”."
            model = genai.GenerativeModel(model_name="gemini-1.0-pro",
                                          generation_config={
                                              "temperature": 0.7,
                                              "max_output_tokens": 150,
                                          })
            try:
                response = model.generate_content([prompt])
                st.session_state.data_collection_method_options = response.text.split('\n')
            except Exception as e:
                st.error(f"API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
                st.session_state.data_collection_method_options = []

        option = st.radio("ë°ì´í„° ìˆ˜ì§‘ ë°©ë²• ì„ íƒì§€", st.session_state.data_collection_method_options + ["ì§ì ‘ ì…ë ¥"], key="data_collection_method")
        if option == "ì§ì ‘ ì…ë ¥":
            option = st.text_input("ë°ì´í„° ìˆ˜ì§‘ ë°©ë²•ì„ ì…ë ¥í•˜ì„¸ìš”:", key="data_collection_method_input")

        if st.button("ë‹¤ìŒ ë‹¨ê³„", key="next_step_5"):
            st.session_state.details.append(f"ë°ì´í„° ìˆ˜ì§‘ ë°©ë²•: {option}")
            st.session_state.step += 1

with right_col:
    st.write("í˜„ì¬ ì…ë ¥ ë‚´ìš©:")
    for detail in st.session_state.details:
        st.write(detail)

# ì—°êµ¬ê³„íšì„œ ìƒì„¸ë³´ê¸° ìƒì„± ë° ì¶œë ¥
if st.session_state.step == 6:
    
    if st.button("ì—°êµ¬ê³„íšì„œ ìƒì„¸ë³´ê¸°", key="generate_plan"):
        prompt = "ë‹¤ìŒ ì—°êµ¬ê³„íšì„œì˜ ìƒì„¸ë³´ê¸°ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”. ì—°êµ¬ ê³„íšì˜ ì¥ì ì„ 3ê°€ì§€ ì•Œë ¤ì£¼ì„¸ìš”. ì—°êµ¬ ìˆ˜í–‰ ì „ ì—°êµ¬ìê°€ ì¶”ê°€ë¡œ ê³ ë ¤ì•¼í•´í•  ì ì„ 1ê°€ì§€ ì•Œë ¤ì£¼ì„¸ìš”.:\n\n" + "\n".join(st.session_state.details)
        model = genai.GenerativeModel(model_name="gemini-1.0-pro",
                                      generation_config={
                                          "temperature": 0.7,
                                          "max_output_tokens": 3000,
                                      })
        try:
            response = model.generate_content([prompt])
            research_plan = response.text
        except Exception as e:
            st.error(f"API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            research_plan = "ìƒì„± ì‹¤íŒ¨"
        
        st.text_area("ì—°êµ¬ê³„íšì„œ ìƒì„¸ë³´ê¸°", research_plan, height=300)
        st.download_button("ì—°êµ¬ê³„íšì„œ ë‹¤ìš´ë¡œë“œ", data=research_plan, file_name="research_plan.txt", mime="text/plain")

if st.button("ë‹¤ì‹œ ì‹œì‘í•˜ê¸°", key="restart"):
    st.session_state.step = 0
    st.session_state.details = []
